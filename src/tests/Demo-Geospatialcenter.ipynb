{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo - Build CRF with Sentinel-2-L2A\n",
    "\n",
    "This notebook demonstrates how to query the STAC API for Sentinel-2 data, process the data to remove cloud pixels, and create a cloud-free composite image using ArcGIS Pro and the ArcGIS Image Analyst extension.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- ArcGIS Pro\n",
    "- ArcGIS Image Analyst extension\n",
    "- Access to the STAC API\n",
    "\n",
    "## Import Libraries\n",
    "\n",
    "First, we import the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "from arcpy import AIO\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Parameters\n",
    "\n",
    "We define the following parameters:\n",
    "\n",
    "- **STAC API URL**: The URL for the STAC API for Sentinel-2 data.\n",
    "- **Path to the Feature Class**: The path to the feature class representing the Area of Interest (AOI).\n",
    "- **Output CRF Path**: The path where the output CRF will be saved.\n",
    "- **Path to the ACS File**: The path to the ACS file for Sentinel-2 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the STAC API URL for Sentinel-2 data\n",
    "stac_api_url = \"https://planetarycomputer.microsoft.com/api/stac/v1\"\n",
    "\n",
    "# Define the path to the feature class representing the AOI\n",
    "aoi_feature_class = r'F:\\ArcGIS Pro Projects\\South_Lebanon\\South_Lebanon.gdb\\lbn_admbnda_adm3'\n",
    "\n",
    "# Define the output CRF path\n",
    "output_crf_path = r'F:\\ArcGIS Pro Projects\\South_Lebanon\\Lebanon_Sentinel2.crf'\n",
    "\n",
    "\n",
    "# Define the path to the ACS file\n",
    "acs_file_path = r'C:\\AMPC_Resources\\ACS_Files\\esrims_pc_sentinel-2-l2a.acs'\n",
    "a_sentinel_2 = AIO(acs_file_path)\n",
    "\n",
    "# Create a feature layer from the projected AOI feature class\n",
    "aoi_layer = \"aoi_layer\"\n",
    "arcpy.MakeFeatureLayer_management(aoi_feature_class, aoi_layer)\n",
    "\n",
    "# Create DatePicker widgets for start and end dates\n",
    "start_date_picker = widgets.DatePicker(\n",
    "    description='Start Date',\n",
    "    disabled=False\n",
    ")\n",
    "end_date_picker = widgets.DatePicker(\n",
    "    description='End Date',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "# Function to update the start and end dates\n",
    "def update_dates(change):\n",
    "    global start_date, end_date\n",
    "    start_date = start_date_picker.value.strftime(\"%Y-%m-%d\")\n",
    "    end_date = end_date_picker.value.strftime(\"%Y-%m-%d\")\n",
    "    print(f\"Start Date: {start_date}, End Date: {end_date}\")\n",
    "\n",
    "# Attach the update function to the DatePicker widgets\n",
    "start_date_picker.observe(update_dates, names='value')\n",
    "end_date_picker.observe(update_dates, names='value')\n",
    "\n",
    "# Display the DatePicker widgets\n",
    "display(start_date_picker, end_date_picker)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the extent of the feature layer\n",
    "extent = arcpy.Describe(aoi_layer).extent\n",
    "# Delete AOI layer\n",
    "arcpy.Delete_management(aoi_layer)\n",
    "\n",
    "bbox_coords = [extent.XMin, extent.YMin, extent.XMax, extent.YMax]\n",
    "\n",
    "# Construct the STAC API query\n",
    "query = {\n",
    "    \"collections\": [\"sentinel-2-l2a\"],\n",
    "    \"bbox\": bbox_coords,\n",
    "    \"query\": {\"platform\": {\"in\": [\"Sentinel-2A\"]}},\n",
    "    \"datetime\": f\"{start_date}/{end_date}\",\n",
    "    \"limit\": 100\n",
    "}\n",
    "\n",
    "# Example attribute_dict for Landsat collection 2 level 2 product\n",
    "attribute_dict = {\n",
    "    \"Name\":\"id\",\n",
    "    \"Cloud Cover\":\"eo:cloud_cover\",\n",
    "    \"StdTime\":\"datetime\",\n",
    "    \"Platform\":\"platform\",\n",
    "    \"Spatial Reference\":\"proj:epsg\",\n",
    "    \"Extent\": \"bbox\",\n",
    "}\n",
    "\n",
    "# Create a RasterCollection object that contains the search results\n",
    "rc = arcpy.ia.RasterCollection.fromSTACAPI(stac_api=stac_api_url,\n",
    "                                           query=query,\n",
    "                                           attribute_dict=attribute_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_cloud(item):\n",
    "    #masks the clouds by the SCL band and also removes the bands we dont need\n",
    "    raster = item['Raster']\n",
    "    try:\n",
    "        thetime = str(item[\"AcquisitionDate\"]).split('T')[0].split('-')\n",
    "        timevar=\"AcquisitionDate\"\n",
    "    except: \n",
    "        thetime = str(item[\"StdTime\"]).split('T')[0].split('-')\n",
    "        timevar=\"StdTime\"\n",
    "        \n",
    "    numtime=int(thetime[0]+thetime[1]+thetime[2])\n",
    "    sclband = arcpy.ia.ExtractBand(raster,[13])\n",
    "    #we dont ned all bands from her on, so lets reduce the bands to what we need ...\n",
    "    reduced_ras=arcpy.ia.ExtractBand(raster,[1,2,3,4,5,6,7,8,9,10,11,12])\n",
    "    #now create a mask-raster by remapping based on the SCL band to take out all NoData, Clouds, CloudShadow, Cirrus, Undefined Pixels\n",
    "    #those values in the SCL band are 0 to 3 and 7 to 10\n",
    "    #as our mask definition always ranges from low[included] to high[excluded], we have to specify\n",
    "    # the Nodata ranges here as [0-4] and [7-11]\n",
    "    cloud_mask=arcpy.ia.Remap(raster=sclband,input_ranges=[4,7,11,15], output_values=[1,1],no_data_ranges=[0,4,7,11],allow_unmatched=False)\n",
    "    #and finally clip the original raster (with all its bands) using the remapped mask dataset    \n",
    "    cloud_free_raster = arcpy.ia.Clip(reduced_ras, aoi = cloud_mask)\n",
    "     #then return the raster back into the now cloud_free Raster collection \n",
    "    return {'raster': cloud_free_raster, \"AcquisitionDate\": item[timevar]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'FeatureCollection',\n",
       " 'features': [],\n",
       " 'links': [{'rel': 'root',\n",
       "   'type': 'application/json',\n",
       "   'href': 'https://planetarycomputer.microsoft.com/api/stac/v1/'},\n",
       "  {'rel': 'self',\n",
       "   'type': 'application/json',\n",
       "   'href': 'https://planetarycomputer.microsoft.com/api/stac/v1/search'}]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the above function to remove cloud pixels from each image in the RasterCollection\n",
    "rc_cloud_free = rc.map(remove_cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the Median function to find the most representative pixels value from overlapping images\n",
    "cloud_free_composite_median = rc_cloud_free.median(ignore_nodata = True, extent_type = 'UnionOf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the Cloud free composite  median\n",
    "cloud_free_composite_median.save(output_crf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import shape\n",
    "\n",
    "def main():\n",
    "    # this is the name of the geography you want to retrieve. update to meet your needs\n",
    "    location = 'Lebanon'\n",
    "\n",
    "    dataset_links = pd.read_csv(\"https://minedbuildings.blob.core.windows.net/global-buildings/dataset-links.csv\")\n",
    "    greece_links = dataset_links[dataset_links.Location == location]\n",
    "    for _, row in greece_links.iterrows():\n",
    "        df = pd.read_json(row.Url, lines=True)\n",
    "        df['geometry'] = df['geometry'].apply(shape)\n",
    "        gdf = gpd.GeoDataFrame(df, crs=4326)\n",
    "        gdf.to_file(f\"{row.QuadKey}.geojson\", driver=\"GeoJSON\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "import os\n",
    "\n",
    "# Define the directory containing the geojson files\n",
    "geojson_directory = r'F:\\ArcGIS Pro Projects\\South_Lebanon\\Buildings\\GeoJson'\n",
    "\n",
    "# Define the output feature class path\n",
    "output_gdb = r'F:\\ArcGIS Pro Projects\\South_Lebanon\\South_Lebanon.gdb'\n",
    "output_feature_class = os.path.join(output_gdb, 'Buildings_Lebanon')\n",
    "\n",
    "# Create a list to store the paths of the geojson files\n",
    "geojson_files = []\n",
    "\n",
    "# Loop through the directory to locate all geojson files\n",
    "for root, dirs, files in os.walk(geojson_directory):\n",
    "    for file in files:\n",
    "        if file.endswith('.geojson'):\n",
    "            geojson_files.append(os.path.join(root, file))\n",
    "\n",
    "# Check if there are any geojson files found\n",
    "if not geojson_files:\n",
    "    print(\"No geojson files found in the specified directory.\")\n",
    "else:\n",
    "    # Create an empty feature class to merge the geojson files into\n",
    "    arcpy.management.CreateFeatureclass(output_gdb, 'Buildings_Lebanon', 'POLYGON', spatial_reference=4326)\n",
    "\n",
    "    # Loop through each geojson file and append it to the feature class\n",
    "    for geojson_file in geojson_files:\n",
    "        temp_fc = 'in_memory/temp_fc'\n",
    "        arcpy.conversion.JSONToFeatures(geojson_file, temp_fc)\n",
    "        arcpy.management.Append(temp_fc, output_feature_class, 'NO_TEST')\n",
    "        arcpy.management.Delete(temp_fc)\n",
    "\n",
    "    print(f\"All geojson files have been merged into the feature class: {output_feature_class}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai-auto-py3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
