{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy.management\n",
    "import requests\n",
    "import zipfile\n",
    "import os\n",
    "import tempfile\n",
    "import datetime\n",
    "import time\n",
    "import arcpy\n",
    "import hashlib\n",
    "import arcpy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions\n",
    "<font color=\"red\">**CAUTION**: Modify the functions below only if you understand the consequences.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def download_and_extract(year):\n",
    "    # Download the zipped file\n",
    "    url = f\"https://sentinel.esa.int/documents/d/sentinel/sentinel-2a-acquisition-plans-{year}\"\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Save the zipped file to a temporary directory\n",
    "    temp_dir = tempfile.mkdtemp()\n",
    "    zip_path = os.path.join(temp_dir, \"sentinel.zip\")\n",
    "    with open(zip_path, \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "    # Extract the zipped file\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(temp_dir)\n",
    "\n",
    "    return temp_dir\n",
    "def calculate_size(cell_size, max_pixels):\n",
    "    # Calculate the size in square meters\n",
    "    size_sqm = (cell_size * max_pixels)**2\n",
    "\n",
    "    # Convert the size to square kilometers\n",
    "    size_sqkm = size_sqm / 1e6\n",
    "\n",
    "    return size_sqkm\n",
    "def create_tessellation(aoi, cell_size, max_pixels):\n",
    "\n",
    "    # Create the tessellation\n",
    "    tessellation = arcpy.GenerateTessellation_management(\n",
    "        Output_Feature_Class=\"tessellation\",\n",
    "        Extent=aoi,\n",
    "        Shape_Type=\"SQUARE\",\n",
    "        Size =  f\"{calculate_size(cell_size, max_pixels)} SquareKilometers\"\n",
    "\n",
    "    )\n",
    "    # return tessellation\n",
    "    # Initialize the list of extents\n",
    "    extents = []\n",
    "\n",
    "    # Assume tessellation is the output from the create_tessellation function\n",
    "    with arcpy.da.SearchCursor(\"tessellation\", [\"SHAPE@\"]) as cursor:\n",
    "        for row in cursor:\n",
    "            feature = row[0]\n",
    "            extent = feature.extent\n",
    "\n",
    "            # Add the extent to the list\n",
    "            extents.append(f'{extent.XMin},{extent.YMin},{extent.XMax},{extent.YMax}')\n",
    "\n",
    "    return extents, tessellation\n",
    "\n",
    "\n",
    "def parse_kml_files(directory, start_date, end_date, aoi):\n",
    "    # Initialize the list of acquisition dates\n",
    "    acq_dates = []\n",
    "    kmlgdbs = []\n",
    "    # Loop through the files in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".kml\"):\n",
    "            # Extract the acquisition dates from the KML file name\n",
    "            acq_start, acq_end = filename.split(\"_\")[5:7]\n",
    "            acq_start = datetime.datetime.strptime(acq_start, \"%Y%m%dT%H%M%S\")\n",
    "            acq_end = datetime.datetime.strptime(acq_end.split(\".\")[0], \"%Y%m%dT%H%M%S\")\n",
    "\n",
    "            # Check if the acquisition dates fall within the defined start and end dates\n",
    "            if start_date <= acq_start <= end_date or start_date <= acq_end <= end_date:\n",
    "                # Convert the KML to a Layer\n",
    "                arcpy.env.workspace = directory\n",
    "\n",
    "                arcpy.conversion.KMLToLayer(os.path.join(directory, filename), directory)\n",
    "\n",
    "                # Loop through all the file geodatabases in the workspace\n",
    "                gdb = [gdb for gdb in arcpy.ListWorkspaces('*', 'FileGDB') if gdb not in kmlgdbs][0]\n",
    "                kmlgdbs.append(gdb)\n",
    "\n",
    "                arcpy.env.workspace = gdb\n",
    "\n",
    "                # Find the polygon feature class in the file geodatabase\n",
    "                \n",
    "                datasets = arcpy.ListDatasets(feature_type='feature')\n",
    "                datasets = [''] + datasets if datasets is not None else []\n",
    "\n",
    "                for ds in datasets:\n",
    "                    for fc in arcpy.ListFeatureClasses(feature_dataset=ds):\n",
    "                        if arcpy.Describe(fc).shapeType == \"Polygon\":\n",
    "                            # Perform a spatial join with the input AOI\n",
    "                            arcpy.analysis.SpatialJoin(\n",
    "                                target_features=f\"{ds}\\\\{fc}\",\n",
    "                                join_features=aoi,\n",
    "                                out_feature_class=\"Join\",\n",
    "                                join_operation=\"JOIN_ONE_TO_ONE\",\n",
    "                                join_type=\"KEEP_ALL\",\n",
    "                                field_mapping=r'Name \"Name\" true true false 320 Text 0 0,First,#,S2 Planned Observations from 20230112T120000 to 20230130T150000\\Polygons,Name,0,319;FolderPath \"FolderPath\" true true false 320 Text 0 0,First,#,S2 Planned Observations from 20230112T120000 to 20230130T150000\\Polygons,FolderPath,0,319;SymbolID \"SymbolID\" true true false 4 Long 0 0,First,#,S2 Planned Observations from 20230112T120000 to 20230130T150000\\Polygons,SymbolID,-1,-1;AltMode \"AltMode\" true true false 2 Short 0 0,First,#,S2 Planned Observations from 20230112T120000 to 20230130T150000\\Polygons,AltMode,-1,-1;Base \"Base\" true true false 8 Double 0 0,First,#,S2 Planned Observations from 20230112T120000 to 20230130T150000\\Polygons,Base,-1,-1;Clamped \"Clamped\" true true false 2 Short 0 0,First,#,S2 Planned Observations from 20230112T120000 to 20230130T150000\\Polygons,Clamped,-1,-1;Extruded \"Extruded\" true true false 2 Short 0 0,First,#,S2 Planned Observations from 20230112T120000 to 20230130T150000\\Polygons,Extruded,-1,-1;TimeSpan \"TimeSpan\" true true false 2 Short 0 0,First,#,S2 Planned Observations from 20230112T120000 to 20230130T150000\\Polygons,TimeSpan,-1,-1;TimeStamp \"TimeStamp\" true true false 2 Short 0 0,First,#,S2 Planned Observations from 20230112T120000 to 20230130T150000\\Polygons,TimeStamp,-1,-1;BeginTime \"BeginTime\" true true false 255 Text 0 0,First,#,S2 Planned Observations from 20230112T120000 to 20230130T150000\\Polygons,BeginTime,0,254;EndTime \"EndTime\" true true false 255 Text 0 0,First,#,S2 Planned Observations from 20230112T120000 to 20230130T150000\\Polygons,EndTime,0,254;Snippet \"Snippet\" true true false 268435455 Text 0 0,First,#,S2 Planned Observations from 20230112T120000 to 20230130T150000\\Polygons,Snippet,0,268435454;PopupInfo \"PopupInfo\" true true false 268435455 Text 0 0,First,#,S2 Planned Observations from 20230112T120000 to 20230130T150000\\Polygons,PopupInfo,0,268435454;Shape_Length \"Shape_Length\" false true true 8 Double 0 0,First,#,S2 Planned Observations from 20230112T120000 to 20230130T150000\\Polygons,Shape_Length,-1,-1;Shape_Area \"Shape_Area\" false true true 8 Double 0 0,First,#,S2 Planned Observations from 20230112T120000 to 20230130T150000\\Polygons,Shape_Area,-1,-1;Shape_Length_1 \"Shape_Length\" false true true 8 Double 0 0,First,#,Cantabria_Boundaries_WGS1984_Pro,Shape_Length,-1,-1;Shape_Area_1 \"Shape_Area\" false true true 8 Double 0 0,First,#,Cantabria_Boundaries_WGS1984_Pro,Shape_Area,-1,-1',\n",
    "                                match_option=\"INTERSECT\",\n",
    "                                search_radius=None,\n",
    "                                distance_field_name=\"\",\n",
    "                                match_fields=None\n",
    "                            )\n",
    "                            # Open a search cursor on the in_memory output\n",
    "                            with arcpy.da.SearchCursor(\"join\", [\"BeginTime\", \"EndTime\"], \"Join_Count = 1\") as cursor:\n",
    "                                for row in cursor:\n",
    "                                    date = row[0].split(\"T\")[0]\n",
    "                                    start_of_day_unix = int(time.mktime(datetime.datetime.strptime(date, '%Y-%m-%d').timetuple())) * 1000\n",
    "                                    end_of_day_unix = start_of_day_unix + 86399999\n",
    "                                    # Append the start date of the filtered features to the acq_dates list\n",
    "                                    acq_dates.append(f\"{start_of_day_unix}, {end_of_day_unix}\")\n",
    "                                del cursor, row\n",
    "                        arcpy.management.Delete(\"join\")\n",
    "                            \n",
    "                arcpy.env.workspace = directory\n",
    "\n",
    "    return acq_dates\n",
    "\n",
    "def generate_token(username, password, referer):\n",
    "    # Define the URL for generating a token\n",
    "    url = \"https://www.arcgis.com/sharing/rest/generateToken\"\n",
    "\n",
    "    # Define the parameters for generating a token\n",
    "    params = {\n",
    "        \"username\": username,\n",
    "        \"password\": password,\n",
    "        \"referer\": referer,\n",
    "        \"f\": \"json\"\n",
    "    }\n",
    "\n",
    "    # Send a POST request to generate a token\n",
    "    response = requests.post(url, params)\n",
    "\n",
    "    # Extract the token from the response\n",
    "    token = response.json()[\"token\"]\n",
    "\n",
    "    return token\n",
    "\n",
    "def download_image(token, acq_date, extent, tessellation, output_dir, username, password):\n",
    "    arcpy.env.overwriteOutput = True\n",
    "\n",
    "    arcpy.SignInToPortal(\"https://www.arcgis.com\", \n",
    "                     username, password)\n",
    "    # Define the URL for exporting an image\n",
    "    url = \"https://sentinel.arcgis.com/arcgis/rest/services/Sentinel2/ImageServer\"\n",
    "    # Convert the acquisition dates from Unix timestamps to the ddMMYYYY format\n",
    "    acq_start, acq_end = acq_date.split(\", \")\n",
    "    acq_start = datetime.datetime.fromtimestamp(int(acq_start) / 1000).strftime(\"%d%m%Y\")\n",
    "    acq_end = datetime.datetime.fromtimestamp(int(acq_end) / 1000).strftime(\"%d%m%Y\")\n",
    "\n",
    "    arcpy.management.MakeImageServerLayer(in_image_service=url, out_imageserver_layer=\"sentinel2_service\", processing_template=\"None\")\n",
    "    arcpy.management.SelectLayerByLocation(in_layer=\"sentinel2_service\", overlap_type=\"INTERSECT\", select_features=tessellation)\n",
    "    arcpy.management.SelectLayerByAttribut(in_layer_or_view=\"sentinel2_service\", selection_type=\"NEW_SELECTION\",\n",
    "                                           where_clause=f\"acquisitiondate >= timestamp '{acq_start}' And acquisitiondate < timestamp '{acq_start + timedelta(days=1)}' And cloudcover < 0.3\")\n",
    "    \n",
    "\n",
    "    acq_start, acq_end = acq_date.split(\", \")\n",
    "    # Generate a unique hash for the extent\n",
    "    extent_hash = hashlib.md5(str(extent).encode()).hexdigest()\n",
    "\n",
    "    with arcpy.EnvManager(extent=f'{extent} PROJCS[\"WGS_1984_Web_Mercator_Auxiliary_Sphere\",GEOGCS[\"GCS_WGS_1984\",DATUM[\"D_WGS_1984\",SPHEROID[\"WGS_1984\",6378137.0,298.257223563]],PRIMEM[\"Greenwich\",0.0],UNIT[\"Degree\",0.0174532925199433]],PROJECTION[\"Mercator_Auxiliary_Sphere\"],PARAMETER[\"False_Easting\",0.0],PARAMETER[\"False_Northing\",0.0],PARAMETER[\"Central_Meridian\",0.0],PARAMETER[\"Standard_Parallel_1\",0.0],PARAMETER[\"Auxiliary_Sphere_Type\",0.0],UNIT[\"Meter\",1.0]]'):\n",
    "        \n",
    "        arcpy.management.SplitRaster(\n",
    "        in_raster=\"sentinel2_service\",\n",
    "        out_folder=output_dir,\n",
    "        out_base_name=f\"sentinel2_{acq_start}_{acq_end}_{extent_hash}\",\n",
    "        split_method=\"SIZE_OF_TILE\",\n",
    "        format=\"TIFF\",\n",
    "        resampling_type=\"NEAREST\",\n",
    "        num_rasters=\"1 1\",\n",
    "        tile_size=\"2048 2048\",\n",
    "        overlap=0,\n",
    "        units=\"PIXELS\",\n",
    "        cell_size=None,\n",
    "        origin=None,\n",
    "        split_polygon_feature_class=None,\n",
    "        clip_type=\"NONE\",\n",
    "        template_extent=\"DEFAULT\",\n",
    "        nodata_value=\"\"\n",
    "    )\n",
    "def process_raster_data(output_dir):\n",
    "    with arcpy.EnvManager(outputCoordinateSystem='PROJCS[\"WGS_1984_Web_Mercator_Auxiliary_Sphere\",GEOGCS[\"GCS_WGS_1984\",DATUM[\"D_WGS_1984\",SPHEROID[\"WGS_1984\",6378137.0,298.257223563]],PRIMEM[\"Greenwich\",0.0],UNIT[\"Degree\",0.0174532925199433]],PROJECTION[\"Mercator_Auxiliary_Sphere\"],PARAMETER[\"False_Easting\",0.0],PARAMETER[\"False_Northing\",0.0],PARAMETER[\"Central_Meridian\",0.0],PARAMETER[\"Standard_Parallel_1\",0.0],PARAMETER[\"Auxiliary_Sphere_Type\",0.0],UNIT[\"Meter\",1.0]]'):\n",
    "        outgdb = os.path.join(output_dir, \"sentinel2.gdb\")\n",
    "        arcpy.management.CreateFileGDB(output_dir, \"sentinel2.gdb\")\n",
    "\n",
    "        arcpy.management.CreateMosaicDataset(\n",
    "            in_workspace=outgdb,\n",
    "            in_mosaicdataset_name=\"sentinel2\",\n",
    "            coordinate_system='PROJCS[\"WGS_1984_Web_Mercator_Auxiliary_Sphere\",GEOGCS[\"GCS_WGS_1984\",DATUM[\"D_WGS_1984\",SPHEROID[\"WGS_1984\",6378137.0,298.257223563]],PRIMEM[\"Greenwich\",0.0],UNIT[\"Degree\",0.0174532925199433]],PROJECTION[\"Mercator_Auxiliary_Sphere\"],PARAMETER[\"False_Easting\",0.0],PARAMETER[\"False_Northing\",0.0],PARAMETER[\"Central_Meridian\",0.0],PARAMETER[\"Standard_Parallel_1\",0.0],PARAMETER[\"Auxiliary_Sphere_Type\",0.0],UNIT[\"Meter\",1.0]]',\n",
    "            num_bands=None,\n",
    "            pixel_type=\"\",\n",
    "            product_definition=\"\",\n",
    "            product_band_definitions=None\n",
    "        )\n",
    "        arcpy.management.AddRastersToMosaicDataset(\n",
    "        in_mosaic_dataset=os.path.join(outgdb, \"sentinel2\"),\n",
    "        raster_type=\"Raster Dataset\",\n",
    "        input_path=f\"{output_dir}\",\n",
    "        update_cellsize_ranges=\"UPDATE_CELL_SIZES\",\n",
    "        update_boundary=\"UPDATE_BOUNDARY\",\n",
    "        update_overviews=\"UPDATE_OVERVIEWS\",\n",
    "        maximum_pyramid_levels=None,\n",
    "        maximum_cell_size=0,\n",
    "        minimum_dimension=1500,\n",
    "        spatial_reference=None,\n",
    "        filter=\"\",\n",
    "        sub_folder=\"SUBFOLDERS\",\n",
    "        duplicate_items_action=\"ALLOW_DUPLICATES\",\n",
    "        build_pyramids=\"BUILD_PYRAMIDS\",\n",
    "        calculate_statistics=\"CALCULATE_STATISTICS\",\n",
    "        build_thumbnails=\"BUILD_THUMBNAILS\",\n",
    "        operation_description=\"\",\n",
    "        force_spatial_reference=\"NO_FORCE_SPATIAL_REFERENCE\",\n",
    "        estimate_statistics=\"ESTIMATE_STATISTICS\",\n",
    "        aux_inputs=None,\n",
    "        enable_pixel_cache=\"NO_PIXEL_CACHE\",\n",
    "    )\n",
    "        \n",
    "    arcpy.management.MakeRasterLayer(os.path.join(outgdb, \"sentinel2\"), \"sentinel2\")\n",
    "\n",
    "    # Define the feature class\n",
    "    fc = \"sentinel2\"\n",
    "\n",
    "    # Add the \"AquisitionDate\" field\n",
    "    arcpy.AddField_management(fc, \"AquisitionDate\", \"DATE\", field_alias=\"Aquisition Date\")\n",
    "\n",
    "    # Define the update cursor\n",
    "    cursor = arcpy.da.UpdateCursor(fc, [\"Name\", \"AquisitionDate\"])\n",
    "    for row in cursor:\n",
    "        if \"Sen\" in row[0]:\n",
    "            # Extract the date string from the field value\n",
    "            date_str = row[0].split(\"_\")[1]\n",
    "\n",
    "            # Convert the date string to a date object\n",
    "            date_obj = datetime.datetime.strptime(date_str, \"%d%m%Y\").date()\n",
    "\n",
    "            # Update the \"AquisitionDate\" field\n",
    "            row[1] = date_obj\n",
    "\n",
    "            # Update the row\n",
    "            cursor.updateRow(row)\n",
    "    del cursor, row\n",
    "    return os.path.join(outgdb, \"sentinel2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define Area of Interest (AOI) and output directory\n",
    "# Change the aoi to the path of the feature class or shapefile that represents the area of interest\n",
    "aoi = r\"D:\\OneDrive - Esri\\Demos & Blogs\\ArcGIS Resources\\GeoAi & Deep Learning\\Demos\\Biomass_Cantabria\\Biomass_Cantabria.gdb\\aoi\"\n",
    "# Change the output_dir to the directory where you want to save the downloaded images and the processed raster data\n",
    "output_dir = r\"C:\\Users\\rami8629\\AppData\\Local\\Temp\\ArcGISProTemp7392\\Untitled\\sentinel2\"\n",
    "\n",
    "#Input AGOL credentials\n",
    "username = input(\"Enter your ArcGIS Online username: \")\n",
    "password = input(\"Enter your ArcGIS Online password: \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the start and end dates\n",
    "start_date = datetime.datetime(2023, 5, 1)\n",
    "end_date = datetime.datetime(2023, 5, 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ExecuteError",
     "evalue": "Failed to execute. Parameters are not valid.\nERROR 000368: Invalid input data.\nFailed to execute (SelectLayerByLocation).\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mExecuteError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_27244\\299499472.py\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0macq_date\u001b[0m \u001b[1;32min\u001b[0m \u001b[0macq_dates\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mextent\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mextents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mdownload_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macq_date\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtessellation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0musername\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpassword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# Process the raster data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_27244\\2703980837.py\u001b[0m in \u001b[0;36mdownload_image\u001b[1;34m(token, acq_date, extent, tessellation, output_dir, username, password)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[0marcpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmanagement\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMakeImageServerLayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_image_service\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_imageserver_layer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"sentinel2_service\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprocessing_template\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"None\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m     \u001b[0marcpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmanagement\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSelectLayerByLocation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_layer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"sentinel2_service\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverlap_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"INTERSECT\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mselect_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtessellation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    146\u001b[0m     arcpy.management.SelectLayerByAttribut(in_layer_or_view=\"sentinel2_service\", selection_type=\"NEW_SELECTION\",\n\u001b[0;32m    147\u001b[0m                                            where_clause=f\"acquisitiondate >= timestamp '{acq_start}' And acquisitiondate < timestamp '{acq_start + timedelta(days=1)}' And cloudcover < 0.3\")\n",
      "\u001b[1;32mc:\\Program Files\\ArcGIS\\Pro\\Resources\\ArcPy\\arcpy\\management.py\u001b[0m in \u001b[0;36mSelectLayerByLocation\u001b[1;34m(in_layer, overlap_type, select_features, search_distance, selection_type, invert_spatial_relationship)\u001b[0m\n\u001b[0;32m  10589\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10590\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m> 10591\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m  10592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10593\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Program Files\\ArcGIS\\Pro\\Resources\\ArcPy\\arcpy\\management.py\u001b[0m in \u001b[0;36mSelectLayerByLocation\u001b[1;34m(in_layer, overlap_type, select_features, search_distance, selection_type, invert_spatial_relationship)\u001b[0m\n\u001b[0;32m  10586\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0marcpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marcobjects\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marcobjectconversion\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconvertArcObjectToPythonObject\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10587\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m> 10588\u001b[1;33m         \u001b[0mretval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvertArcObjectToPythonObject\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSelectLayerByLocation_management\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mgp_fixargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_layer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverlap_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mselect_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msearch_distance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mselection_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minvert_spatial_relationship\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m  10589\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10590\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Program Files\\ArcGIS\\Pro\\Resources\\ArcPy\\arcpy\\geoprocessing\\_base.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    518\u001b[0m         \u001b[0mval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 520\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mgp_fixargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    521\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mconvertArcObjectToPythonObject\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mExecuteError\u001b[0m: Failed to execute. Parameters are not valid.\nERROR 000368: Invalid input data.\nFailed to execute (SelectLayerByLocation).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "years = list(range(start_date.year, end_date.year+1))\n",
    "\n",
    "for year in years:\n",
    "    temp_dir = download_and_extract(year)\n",
    "\n",
    "acq_dates = parse_kml_files(temp_dir, start_date, end_date, aoi)\n",
    "acq_dates = list(set(acq_dates))\n",
    "\n",
    "extents, tessellation = create_tessellation(aoi, 10, 2048)\n",
    "\n",
    "# Generate a token\n",
    "token = generate_token(username, password, \"https://www.arcgis.com\")\n",
    "\n",
    "\n",
    "# Loop through the list of acquisition dates and extents\n",
    "for acq_date in acq_dates:\n",
    "    for extent in extents:\n",
    "        download_image(token, acq_date, extent, tessellation, output_dir, username, password)\n",
    "\n",
    "# Process the raster data\n",
    "out_mosaic = process_raster_data(output_dir)\n",
    "\n",
    "print(f\"Processed raster data saved to {out_mosaic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rami8629\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "from arcgis.gis import GIS\n",
    "from arcgis.raster import ImageryLayer\n",
    "from arcgis.raster.functions import apply\n",
    "import hashlib\n",
    "import datetime\n",
    "\n",
    "output_dir = r\"E:\\OneDrive - Esri\\Demos & Blogs\\ArcGIS Resources\\GeoAi & Deep Learning\\Demos\\Biomass_Cantabria\\Sentinel2_15Bands\"\n",
    "username = \"ralouta.aiddev\"\n",
    "password = input(\"Enter your ArcGIS Online password: \")\n",
    "# Sign in to ArcGIS Online\n",
    "gis = GIS(\"https://www.arcgis.com\", username, password)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sentinel_item=gis.content.search('255af1ceee844d6da8ef8440c8f90d00', 'Imagery Layer', outside_org=True)[0]\n",
    "s2_layer = sentinel_item.layers[0]\n",
    "sentinel_AllBands = apply(s2_layer, 'None')\n",
    "# acq_date = f'{1685484000000}, {int(1688076000000+(43200000*1.5))}'\n",
    "acq_date = '1685484000000, 1685548800000'\n",
    "extent = '-523457.48640000075,5350736.778700002,-520897.48640000075,5353296.778700002'\n",
    "# Convert the acquisition dates from Unix timestamps to the ddMMYYYY format\n",
    "acq_start, acq_end = acq_date.split(\", \")\n",
    "acq_start = datetime.datetime.fromtimestamp(int(acq_start) / 1000).strftime(\"%d%m%Y\")\n",
    "acq_end = datetime.datetime.fromtimestamp(int(acq_end) / 1000).strftime(\"%d%m%Y\")\n",
    "\n",
    "# Generate a unique hash for the extent\n",
    "extent_hash = hashlib.md5(str(extent).encode()).hexdigest()\n",
    "\n",
    "# Define the output filename\n",
    "out_file = f\"sentinel2_{acq_start}_{acq_end}_{extent_hash}.tif\"\n",
    "\n",
    "# Export the image\n",
    "image = sentinel_AllBands.export_image(bbox=extent, \n",
    "                     save_folder=output_dir, \n",
    "                     save_file=out_file, \n",
    "                     image_sr=3857, \n",
    "                     bbox_sr=3857, \n",
    "                     size=[250, 250],\n",
    "                     time=acq_date,\n",
    "                     f=\"image\", \n",
    "                     export_format=\"tiff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1688076000000, 1688140800000'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acq_date"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
