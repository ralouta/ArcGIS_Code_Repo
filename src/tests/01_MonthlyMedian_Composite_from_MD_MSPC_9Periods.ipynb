{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create MosaicDataset(s) and MultiDim cloud-free composite from Sentinel-2 on MS Planetary Computer - 9 timePeriod version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This version of the workflow is based on a Polygon FeatureClass defining the areas to use. \n",
    "It will cycle through this FeatureClass to create MosaicDatasets of Sentinel-2 based on MSPC.\n",
    "It will then, based on these Mosaic Datasets, create Multidimensional CRFs with monthly averages of three Indixes (EVI, NDMI, MCARI-mod) as 3band timeslices OR 7bands as described in the PSETAE model.\n",
    "These resulting CRFs are the basis for Training a crop detection deep Learning model using the PSETAE model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the modules used in this Notebook\n",
    "import arcpy\n",
    "from arcpy.ia import *\n",
    "import os,sys\n",
    "from datetime import datetime\n",
    "import json\n",
    "#writers decision :)\n",
    "arcpy.env.overwriteOutput=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use a little trick to get the local folder of this notebook as the reference base path\n",
    "#all paths then deducted from that\n",
    "from base_fns import get_local_folder\n",
    "base_path = get_local_folder()\n",
    "print('This notebook and all code in: {}'.format(base_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs to run this.\n",
    "# there should be no need to make any changes besides in THIS field\n",
    "#-----------------#\n",
    "\n",
    "'''Important paths first - as this runs in an MDCS folder structure'''\n",
    "'''------------------------------------------------------------------'''\n",
    "#specific to mdcs\n",
    "#as this is a custom version of the sentinel-2 workflow, special path!\n",
    "#solutionLib_path=r'E:\\Projects\\CropDetection_PSETAE\\mdcsworkflow\\Sentinel2custom\\scripts'\n",
    "solutionLib_path=os.path.join(os.path.dirname(base_path),'mdcsworkflow\\Sentinel2custom\\scripts')\n",
    "#this path spec is needed for the MDCS calls - please adjust if needed\n",
    "pythonPath=r\"C:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\python.exe\"\n",
    "configBase = os.path.join(os.path.dirname(solutionLib_path), \"Parameter\",\"Config\")\n",
    "rftBase=os.path.join(os.path.dirname(solutionLib_path), \"Parameter\",\"RasterFunctionTemplates\")\n",
    "sys.path.append(solutionLib_path)\n",
    "#now that ball this is set, import MDCS\n",
    "import MDCS\n",
    "\n",
    "'''Some cloud and data selection specific specific settings'''\n",
    "'''---------------------------------------------------------'''\n",
    "#Where is the MSPC ACS file\n",
    "#acs_filepath=r\"E:\\ACSFiles\\esrims_pc_sentinel2-l2a.acs\"\n",
    "acs_filepath=os.path.join(os.path.dirname(base_path),'mdcsworkflow\\Sentinel2custom\\Parameter\\Credentials','esrims_pc_sentinel2-l2a.acs')\n",
    "#max acceptable cloud_cover in % value\n",
    "max_clouds=30\n",
    "#The cloud we use\n",
    "cloud_type=\"azure\"\n",
    "#Do we provide a list of scenes\n",
    "inlist='None'\n",
    "#the coordinate system we hand the extents over - we use wgs84\n",
    "project_WKID=4326\n",
    "\n",
    "'''Setting for the time period/year and time slices to use'''\n",
    "'''----------------------------------------------------------'''\n",
    "#the year this will work on - as a string\n",
    "theyear='2023'\n",
    "#define the time_slices we want to operate on - mid_month sequences from March through October\n",
    "#timeranges=[[theyear+'-02-15',theyear+'-03-14',theyear+'-03-01'],[theyear+'-03-15',theyear+'-04-14',theyear+'-04-01'],\n",
    "#            [theyear+'-04-15',theyear+'-05-14',theyear+'-05-01'],[theyear+'-05-15',theyear+'-06-14',theyear+'-06-01'],\n",
    "#            [theyear+'-06-15',theyear+'-07-14',theyear+'-07-01'],[theyear+'-07-15',theyear+'-08-14',theyear+'-08-01'],\n",
    "#            [theyear+'-08-15',theyear+'-09-14',theyear+'-09-01'],[theyear+'-09-15',theyear+'-10-14',theyear+'-10-01'],\n",
    "#            [theyear+'-10-15',theyear+'-11-14',theyear+'-11-01']]\n",
    "#define the time_slices we want to operate on - start/end/label 25day sequences mid from March through early Nov\n",
    "timeranges=[[theyear+'-03-10',theyear+'-04-10',theyear+'-03-25'],[theyear+'-04-11',theyear+'-05-06',theyear+'-04-24'],\n",
    "            [theyear+'-05-07',theyear+'-06-02',theyear+'-05-20'],[theyear+'-06-03',theyear+'-06-28',theyear+'-06-15'],\n",
    "            [theyear+'-06-29',theyear+'-07-24',theyear+'-07-12'],[theyear+'-07-25',theyear+'-08-19',theyear+'-08-10'],\n",
    "            [theyear+'-08-20',theyear+'-09-15',theyear+'-09-03'],[theyear+'-09-16',theyear+'-10-10',theyear+'-09-29'],\n",
    "            [theyear+'-10-10',theyear+'-11-04',theyear+'-10-23']]\n",
    "\n",
    "\n",
    "'''The polygon FC that defines the regions/areas for which MDs and CRFs are to be produced'''\n",
    "'''------------------------------------------------------------------------------------------'''\n",
    "#the regions-polygons used to define the different sub-areas\n",
    "boundary_FC=os.path.join(os.path.dirname(base_path),'data\\input\\ATAereas\\LWHPG','STATISTIK_AUSTRIA_LWHPG_20230101_plus.shp')\n",
    "#the list of features and assigned names for the regions inside this FC to use - identifier is the FID\n",
    "#we use shorter names instead of the real names in the FC!\n",
    "#this shows [Identifier,Name] and this s the ultimate list to process\n",
    "#area_list=[['1','Voralpen'],['2','Alpenostrand'],['3','Muehlviertel'],['4','Kaernten'],['5','Alpenvorland'],['6','Styria'],['7','Burgenland']]\n",
    "#for partial processing and tests, just use partial lists\n",
    "#there are also two test areas in the dataset:\n",
    "#area_list=[['8','smallTest'],['9','largerTest']]\n",
    "area_list=[['8','smallTest'],['9','LargerTest']]\n",
    "#To create a buffered project boundary, specify a buffer-size for the outside buffer - 100 (m) default\n",
    "buffer_size=100\n",
    "#We currently dont use the MDCS feature to hand over a list of sentinel scenes as a list\n",
    "in_list='None'\n",
    "\n",
    "'''Output location and basename'''\n",
    "'''-------------------------------'''\n",
    "#The folder path for the fGDB where the the created Mosaics will reside\n",
    "FGDB_Folder=os.path.join(os.path.dirname(base_path),'data\\output\\\\fGDBs') \n",
    "#The fGDB name where the different Mosaics reside\n",
    "FGDB_Name='AT_CropRegion_S2_MDs_2023.gdb'\n",
    "#the final output-path for the Multidimensional CRFs\n",
    "# be ware they are big - but rather dont save them on the ephemeral drive!\n",
    "RESULT_Folder=os.path.join(os.path.dirname(base_path),'data\\output\\MDimRasters') \n",
    "#specify a TEMP path - on MSPC computer, recommended to use the ephemeral Z Drive\n",
    "TEMP_Folder=r'z:\\temp'\n",
    "\n",
    "'''Some processing-specific settings'''\n",
    "#there currently is an issue with the <GeometricMedia> function. However, in the future, once this is fixed\n",
    "#this is the preferred function to use. For now we use the normal <Median> or <MEAN>. This switch will allow to change that\n",
    "# set this to either 'MEAN, 'MEDIAN' or 'GEOMETRIC'\n",
    "average_to_use='MEAN'#using MEAN as there are not enough rasters for a senseful median\n",
    "#output_bands to produce: We try with 3 index based bands, called '3IDX' here. If that does not work, we return to the\n",
    "#PSETAE recommendation of '7BND'\n",
    "output_band_mode='7BND'\n",
    "#the md's for the areas only have to be built once, turn the switch on here to build them\n",
    "#currently they are allbuild and as they are for 2023, there wont be additional scenes available, unless cloud-% is changed\n",
    "# md_mode can be 'BUILD_MD' or 'NO_BUILD_MD'\n",
    "#md_mode='NO_BUILD_MD'\n",
    "md_mode='BUILD_MD'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>DONT CHANGE ANYTHING BELOW HERE UNLESS YOU KNOW WHAT YOU ARE DOING :)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all repeated sub_routines used in this Notebook#\n",
    "#-----------------------------------------------#\n",
    "\n",
    "'''Get an extent string projected into target WKID'''\n",
    "'''--------------------------------------------------'''\n",
    "def return_projected_feature_layer_extent(in_fc, in_query,out_WKID):\n",
    "    theLyr= arcpy.MakeFeatureLayer_management(in_fc, 'myLyr',in_query)\n",
    "    desc=arcpy.Describe(in_fc)\n",
    "    in_sr=desc.spatialReference\n",
    "\n",
    "    with arcpy.da.SearchCursor(theLyr,['Shape@']) as cursor:\n",
    "        for row in cursor:\n",
    "            e= row[0].extent\n",
    "            e_points = [\n",
    "                arcpy.Point(e.XMin, e.YMin),\n",
    "                arcpy.Point(e.XMax, e.YMax),\n",
    "                ]\n",
    "            e_geometry = arcpy.Polyline(arcpy.Array(e_points), in_sr)\n",
    "            out_geometry= e_geometry.projectAs(arcpy.SpatialReference(out_WKID)).extent\n",
    "            out_geometry = str(out_geometry).split('NaN')[0].strip()\n",
    "            arcpy.Delete_management(theLyr)\n",
    "            return (out_geometry)\n",
    "        \n",
    "'''Create single MD - many things hardcoded'''\n",
    "'''------------------------------------------'''\n",
    "#this uses the MDCS workfow for Sentinel-2 on MSPC that is customized and copied into this project\n",
    "#as a folder called 'mdcsworkflows'\n",
    "def md_from_poly_and_MSPC(out_MD_name,out_query,out_extent):\n",
    "    #import MDCS\n",
    "    #NOTE: There is a custom routine for boundary cleaning and Footprint clipping used!\n",
    "    cmdList=\"sentinel2+CM+embed_acs+AR+IG+CV+SP+bndimport\"\n",
    "    configName=os.path.join(configBase,'sentinel2l2A.xml')\n",
    "    out_MD=os.path.join(FGDB_Folder,FGDB_Name,out_MD_name)\n",
    "    startdate=timeranges[0][0]\n",
    "    enddate=timeranges[-1][1]\n",
    "    args = [\n",
    "           '#gprun',\n",
    "            f'-m:{out_MD}',\n",
    "            f'-i:{configName}',\n",
    "            f'-c:{cmdList}',\n",
    "            f'-p:{startdate}$startdate',\n",
    "            f'-p:{enddate}$enddate',\n",
    "            f'-p:{out_extent}$aoi',\n",
    "            f'-p:{project_WKID}$aoisrs',\n",
    "            f'-p:{max_clouds}$cloudcover',\n",
    "            f'-p:{cloud_type}$cloud_type',\n",
    "            f'-p:{acs_filepath}$acs_filepath',\n",
    "            f'-p:{in_list}$inlist',\n",
    "            f'-p:{buffer_size}$buffersize',\n",
    "            f'-p:{boundary_FC}$sourcefc',\n",
    "            f'-p:{out_query}$sourcequery',        \n",
    "            ]    \n",
    "\n",
    "    #now ready to run\n",
    "    argc = len(args)\n",
    "    ret = MDCS.main(argc, args) \n",
    "    return True\n",
    "    \n",
    "'''Define function to remove cloud pixels based on QA band - bands hardcoded'''\n",
    "'''--------------------------------------------------------------------------'''\n",
    "#Also masks out anything outside the defined polygon geometry that is the boundary of the input polygon\n",
    "def remove_cloud(item):#also clips to project area!\n",
    "    raster = item['Raster']\n",
    "    #clip to project boundary\n",
    "    raster_clipped = arcpy.ia.Clip(raster, aoi = in_boundary)\n",
    "    #all_bands=raster.getRasterBands()\n",
    "    #for band in all_bands:\n",
    "    #    print (band.name)\n",
    "    #return False    \n",
    "    sclband = raster.getRasterBands(['Band_15'])\n",
    "    #print ('{},{},{},{}'.format(scl_band.name,scl_band.isInteger,scl_band.pixelType,scl_band.computeStatistics()))\n",
    "    #first clip this mask to the project boundary\n",
    "    sclband_clipped = arcpy.ia.Clip(sclband,aoi=in_boundary) \n",
    "    #now remap based on the SCL band to take out all NoData, Clouds, CloudShadow, Water, Cirrus, Undefined Pixels\n",
    "    cloud_mask=arcpy.ia.Remap(raster=sclband,input_ranges=[4,6,11,15], output_values=[1,1],no_data_ranges=[0,4,6,11],allow_unmatched=False)\n",
    "    #with arcpy.EnvManager(rasterStatistics=\"STATISTICS 128 128\", resamplingMethod=\"BILINEAR\", tileSize=\"512 512\", pyramid=\"PYRAMIDS -1 NEAREST LZ77 75 SKIP_FIRST NO_SIPS\", processorType=\"CPU\", parallelProcessingFactor=\"80%\"):\n",
    "    #    arcpy.management.CopyRaster(in_raster=cloud_mask, out_rasterdataset=os.path.join(r'Z:\\temp','remap_'+str(item[\"Name\"])+'.crf'),  format='CRF') \n",
    "    #and finally clip the original raster (with all its bands) using the remapped dataset    \n",
    "    cloud_free_raster = arcpy.ia.Clip(raster_clipped, aoi = cloud_mask)\n",
    "    #with arcpy.EnvManager(rasterStatistics=\"STATISTICS 128 128\", resamplingMethod=\"BILINEAR\", tileSize=\"512 512\", pyramid=\"PYRAMIDS -1 NEAREST LZ77 75 SKIP_FIRST NO_SIPS\", processorType=\"CPU\", parallelProcessingFactor=\"80%\"):\n",
    "    #    arcpy.management.CopyRaster(in_raster=cloud_free_raster, out_rasterdataset=os.path.join(r'Z:\\temp','clip_'+str(item[\"Name\"])+'.crf'),  format='CRF')\n",
    "    #then return the raster back into the now cloud_free and clipped Raster collection    \n",
    "    return {'raster': cloud_free_raster, \"Name\": item[\"Name\"], \"AcquisitionDate\": item[\"AcquisitionDate\"]}    \n",
    "\n",
    "\n",
    "'''The BINARY_MASK function just creates a mask: Where there is a value, make it one, else, NoData'''\n",
    "'''-------------------------------------------------------------------------------------------------'''\n",
    "#this can be used to debug the availability of all time-slices in an area. NOT part of the regular workflow\n",
    "#see commented out part at the end\n",
    "def BINARY_MASK(item):\n",
    "    # Create the raster object from the item of one of the resulting images\n",
    "    #as we only care for NoData, this version should work for all types\n",
    "    raster = item['Raster']\n",
    "    #for 3IDX the we use the NDMI\n",
    "    if output_band_mode=='3IDX':\n",
    "        sel_band=raster.getRasterBands([\"NDMI\"])\n",
    "    else:#the 7band option\n",
    "        sel_band=raster.getRasterBands([\"Red\"])       \n",
    "    binary_mask=arcpy.ia.Remap(raster=sel_band,input_ranges=[-65535,65535], output_values=[1],allow_unmatched=False)\n",
    "    #if you want to debug\n",
    "    #out_p=r'c:\\temp\\bm'+str(item['StdTime'][:10])+'.tif'\n",
    "    #print (out_p)\n",
    "    #arcpy.management.CopyRaster(binary_mask, out_p, config_keyword=None, background_value=None, nodata_value=0, format='COG')\n",
    "    return {\"raster\": binary_mask, \"StdTime\": item['StdTime']}\n",
    "\n",
    "\n",
    "'''Calculate 3 indices as three bands ... maybe add others ... ? work in progress'''\n",
    "'''------------------------------------------------'''\n",
    "#the definition of the indices used - work in progress - not used for now\n",
    "def ThreeIndices(item):\n",
    "    raster=item['Raster']\n",
    "    #we need to store those away - might be too big for memory!\n",
    "    outpath=os.path.join(TEMP_Folder,'threeIndixces_'+item['datestr']+'.tif')\n",
    "    #get all bands used in the three indixces\n",
    "    blue,green,red,rededge,nir,swir = raster.getRasterBands([\"Band_2\",\"Band_3\",\"Band_4\",\"Band_5\",\"Band_8\",\"Band_11\"])\n",
    "    #evi - sort of similar to ndvi - bringing to suitable 16 bit range by multiplying by 10000\n",
    "    EVI = (2.5*(((nir - red) / (nir + 6*red - 7.5*blue)) + 1))*10000\n",
    "    #EVI = 2.5*(((nir - red) / (nir + 6*red - 7.5*blue)) + 1)#org formula\n",
    "    for bname in EVI.bandNames:\n",
    "        EVI.renameBand(bname, 'EVI')\n",
    "    #NDMI\n",
    "    NDMI = (nir-swir)/(nir+swir)*10000 #*10000\n",
    "    #NDMI = (nir-swir)/(nir+swir)#org formula\n",
    "    \n",
    "    for bname in NDMI.bandNames:\n",
    "        NDMI.renameBand(bname, 'NDMI')\n",
    "    #mcari, additionally divided by 100 to better fit the scale of EVI and NDMI\n",
    "    #MCARI=(((rededge-red)-0.2*(rededge-green))*(rededge/red))/100 #org formula/100\n",
    "    MCARI=(((rededge-red)-0.2*(rededge-green))*(rededge/red))*100 #org formula*100\n",
    "  \n",
    "    for bname in MCARI.bandNames:\n",
    "        MCARI.renameBand(bname, 'MCARI')    \n",
    "    #create a 3band outraster from it\n",
    "    raslist=[EVI,NDMI,MCARI]\n",
    "    #raslist.append(EVI)\n",
    "    #raslist.append(NDMI)\n",
    "    #raslist.append(MCARI)\n",
    "    outras=arcpy.CompositeBands_management(raslist,outpath)  \n",
    "    #print (\"Little debug report: month {}, datestr {}, StdTime {}\".format(item['month'],item['datestr'],item['StdTime']))\n",
    "    #as the name will be used as the variable, dont create a name per raster like this ...\n",
    "    #namestr=f\"idx3_{item['month']}\"\n",
    "    #but use a constant as the name\n",
    "    return {\"raster\": outras, \"name\": \"idx3_composite\",\"datestr\": item['datestr'],\"StdTime\": item['StdTime']}\n",
    "\n",
    "'''Return 7 Bands'''\n",
    "'''------------------------------------------------'''\n",
    "#limit output to 7bands\n",
    "def SevenBands(item):\n",
    "    raster=item['Raster']\n",
    "    #we need to store those away - might be too big for memory!\n",
    "    outpath=os.path.join(TEMP_Folder,'sevenBands_'+item['datestr']+'.tif')\n",
    "    #get all bands needed\n",
    "    blue,green,red,rededge,nir,swir1,swir2=raster.getRasterBands([\"Band_2\",\"Band_3\",\"Band_4\",\"Band_7\",\"Band_8\",\"Band_11\",\"Band_12\"])\n",
    "    #create a 7band outraster from it\n",
    "    raslist=[blue,green,red,rededge,nir,swir1,swir2]\n",
    "    outras=arcpy.CompositeBands_management(raslist,outpath)  \n",
    "    #as the name will be used as the variable, dont create a name per raster like this ...\n",
    "    #namestr=f\"idx3_{item['month']}\"\n",
    "    #but use a constant as the name\n",
    "    return {\"raster\": outras, \"name\": \"bnd7_composite\",\"datestr\": item['datestr'],\"StdTime\": item['StdTime']}\n",
    "\n",
    "'''The routine that takes the output MDIM-Raster and creates a single\n",
    "polygon from it that delineates the area of the image that has data for every single time-slice'''\n",
    "def create_full_coverage_polygon(in_mdim_raster_path,item_name,in_year):\n",
    "    time_reporter('Create full coverage mask and polygon')\n",
    "    rc_for_remap=arcpy.ia.RasterCollection(in_mdim_raster_path)\n",
    "    slice_count=int(rc_for_remap.count)\n",
    "    print (slice_count)\n",
    "    print ('New Collection has {} images'.format(slice_count))\n",
    "    print ('Fields in collection: {}'.format(rc_for_remap.fields))\n",
    "    rc_remapped=rc_for_remap.map(BINARY_MASK)\n",
    "    #clean up\n",
    "    del rc_for_remap\n",
    "    #now summarize and remap the result again\n",
    "    rc_sum=rc_remapped.sum()  \n",
    "    #clean up\n",
    "    del rc_remapped\n",
    "    #here you can decide how tolerable to be. ALL TimeSlices would be only accepting pixels with value 7\n",
    "    #for succesful export of training samples this is needed\n",
    "    rc_mask=arcpy.ia.Remap(raster=rc_sum,input_ranges=[slice_count,slice_count+1], output_values=[1],no_data_ranges=[0,slice_count,slice_count+1,slice_count+10],allow_unmatched=False)\n",
    "    #rc_mask=arcpy.ia.Remap(raster=rc_sum,input_ranges=[9,10], output_values=[1],no_data_ranges=[0,6,8,10],allow_unmatched=False)\n",
    "    #clean up\n",
    "    del rc_sum\n",
    "    rc_mask_outpath=os.path.normpath(os.path.join(TEMP_Folder,item_name+'_coverage_mask.tif'))\n",
    "    #arcpy.management.CopyRaster(rc_mask, rc_mask_outpath, nodata_value=0, pixel_type=\"8_BIT_UNSIGNED\", scale_pixel_value=\"ScalePixelValue\", format='COG')\n",
    "    arcpy.management.CopyRaster(rc_mask, rc_mask_outpath, nodata_value=0, pixel_type=\"8_BIT_UNSIGNED\", format='COG')\n",
    "    #clean up\n",
    "    del rc_mask\n",
    "    #now make this raster to Polygon - in Temp-Space, as we'll buffer inside later\n",
    "    out_temp_poly=os.path.join(FGDB_Folder,FGDB_Name,item_name+'_tempArea')\n",
    "    #out_temp_poly=r'memory\\temp_'+item_name+'_allTimeslices'\n",
    "    arcpy.conversion.RasterToPolygon(\n",
    "    in_raster=rc_mask_outpath,\n",
    "    out_polygon_features=out_temp_poly,\n",
    "    simplify=\"SIMPLIFY\",\n",
    "    raster_field=\"Value\",\n",
    "    create_multipart_features=\"MULTIPLE_OUTER_PART\",\n",
    "    max_vertices_per_feature=None\n",
    "    )\n",
    "    #now define and write the final polygon feature class\n",
    "    out_final_fc=os.path.join(FGDB_Folder,FGDB_Name,item_name+'_'+in_year+'_AllTimeSlicesArea')\n",
    "    arcpy.analysis.Buffer(\n",
    "        in_features=out_temp_poly,\n",
    "        out_feature_class=out_final_fc,\n",
    "        buffer_distance_or_field=\"-100 Meters\",\n",
    "        line_side=\"FULL\",\n",
    "        line_end_type=\"ROUND\",\n",
    "        dissolve_option=\"ALL\",\n",
    "        dissolve_field=None,\n",
    "        method=\"PLANAR\"\n",
    "        )\n",
    "    #another final cleanup\n",
    "    try:\n",
    "        arcpy.Delete_management(rc_mask_outpath)\n",
    "        arcpy.Delete_management(out_temp_poly)\n",
    "    except Exception as exp:\n",
    "        print ('delete error {}'.format(exp))\n",
    "        pass\n",
    "    print ('Final Coverage FC written to: {}'.format(out_final_fc))\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "'''attach rft-template to an existing raster (not MD)'''\n",
    "'''----------------------------------------------------'''\n",
    "#depending on output, define templates here and attach\n",
    "def append_rfts_to_raster(in_ras):\n",
    "    #if not a raster but a string is handed over, make it the raster we need\n",
    "    if 'str' in str(type(in_ras)): #make it a raster\n",
    "        mdim_raster=arcpy.Raster(in_ras)\n",
    "        \n",
    "    else: #it likely is a raster already\n",
    "        mdim_raster=in_ras  \n",
    "    rftlist=[]\n",
    "    if output_band_mode=='3IDX':\n",
    "        rftlist.append(os.path.normpath(os.path.join(rftBase,'As3Band.rft.xml')))\n",
    "        rftlist.append(os.path.normpath(os.path.join(rftBase,'ExtractEVI.rft.xml')))\n",
    "        rftlist.append(os.path.normpath(os.path.join(rftBase,'ExtractNDMI.rft.xml')))\n",
    "        rftlist.append(os.path.normpath(os.path.join(rftBase,'ExtractMCARI.rft.xml'))) \n",
    "    else: #the 7 band usecase, use all 7bands as default, and add 3 visual bands with DRA\n",
    "        rftlist.append(os.path.normpath(os.path.join(rftBase,'All7Bands.rft.xml')))       \n",
    "        rftlist.append(os.path.normpath(os.path.join(rftBase,'SimpleRGB_DRA.rft.xml')))\n",
    "    #now mod the raster\n",
    "    for rft in rftlist:\n",
    "        if mdim_raster.functions is None:\n",
    "            flist=[]\n",
    "            flist.append(rft)\n",
    "        else:\n",
    "            flist=mdim_raster.functions\n",
    "            flist.append(rft)\n",
    "        mdim_raster.functions=flist\n",
    "    try:\n",
    "        mdim_raster.save(mdim_raster.catalogPath)\n",
    "    except:\n",
    "        pass\n",
    "    return None   \n",
    "\n",
    "\n",
    "'''Reassigning the Band names by the selected band output option'''\n",
    "'''-----------------------------'''\n",
    "def reassign_band_names(in_ras):\n",
    "    #if not a raster but a string is handed over, make it the raster we need\n",
    "    if 'str' in str(type(in_ras)): #make it a raster\n",
    "        mdim_raster=arcpy.Raster(in_ras)\n",
    "    else: #it likely is a raster already\n",
    "        mdim_raster=in_ras\n",
    "    if output_band_mode=='3IDX':\n",
    "        try:\n",
    "            mdim_raster.renameBand('Band_1', 'EVI')\n",
    "            mdim_raster.renameBand('Band_2', 'NDMI')\n",
    "            mdim_raster.renameBand('Band_3', 'MCARI')\n",
    "        except:\n",
    "            pass\n",
    "    else: #the 7 band result  blue,green,red,rededge,nir,swir1,swir2    \n",
    "        try:\n",
    "            mdim_raster.renameBand('Band_1', 'Blue')\n",
    "            mdim_raster.renameBand('Band_2', 'Green')\n",
    "            mdim_raster.renameBand('Band_3', 'Red')\n",
    "            mdim_raster.renameBand('Band_4', 'Red Edge 3')\n",
    "            mdim_raster.renameBand('Band_5', 'Nir')\n",
    "            mdim_raster.renameBand('Band_6', 'Swir 1')\n",
    "            mdim_raster.renameBand('Band_7', 'Swir 2')\n",
    "        except Exception as exp:\n",
    "            print (exp)\n",
    "            pass  \n",
    "    return None\n",
    "\n",
    "'''A little time reporter'''\n",
    "'''-----------------------'''\n",
    "#just keeping code shorter\n",
    "def time_reporter(in_topic_string):\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(\"{} started at: {}\".format(in_topic_string, current_time))\n",
    "    return None        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build all the mosaics - this just needs to be done once, thats why it is taken out of the larger routine below\n",
    "for item in area_list:\n",
    "    the_query='FID = '+item[0]\n",
    "    the_name=item[1]+'_'+theyear\n",
    "    the_ext=return_projected_feature_layer_extent(boundary_FC, the_query,project_WKID)\n",
    "    if md_mode=='NO_BUILD_MD':\n",
    "        print ('Listing MD {}: {}, Extent is {}'.format(the_name,the_query,the_ext))\n",
    "    else: #BUILD MODE    \n",
    "        print ('Building MD ... {}: {}, Extent is {}'.format(the_name,the_query,the_ext))\n",
    "        md_from_poly_and_MSPC(the_name,the_query,the_ext)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='orange'>!!!BELOW IS THE MAIN LOOP - THIS CAN/WILL TAKE CONSIDERABLE TIME, HOURS! AND MORE TO COMPLETE!!!</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# THE MAIN ROUTINE LOOP\n",
    "#we build the analytics on top of an existing Mosaic Datasets, \n",
    "# pre-requisit is thus having run the code-block above to create the Mosaics\n",
    "# based on the area_list we now cycle though the Mosaics and do all the work ...\n",
    "#arcpy.Delete_management(in_md_layer)\n",
    "#arcpy.Delete_management('in_MDLayer')\n",
    "for item in area_list:\n",
    "    input_md=os.path.join(FGDB_Folder,FGDB_Name,item[1]+'_'+theyear)\n",
    "    print('-----------------------------------------------')\n",
    "    print ('Working on MosaicDataset {}'.format(input_md))\n",
    "    print('-----------------------------------------------')\n",
    "    time_reporter('Process main loop')\n",
    "    #now get the polygon of the boundary right away to use for clipping\n",
    "    in_md_layer = arcpy.MakeMosaicLayer_management(input_md, 'in_MDLayer')\n",
    "    in_boundary = 'in_MDLayer\\Boundary'\n",
    "    #create the raster collection and report on it\n",
    "    my_col=arcpy.ia.RasterCollection(input_md)\n",
    "    print ('Collection has {} images'.format(my_col.count))\n",
    "    print ('Fields in collection: {}'.format(my_col.fields))\n",
    "    #split the rc up into the monthly pieces and create averaged corrected versions per time period\n",
    "    monthly_rasters=[]\n",
    "    monthly_dates=[]\n",
    "    #cycle through all time_ranges\n",
    "    print ('-------------------------------')\n",
    "    print ('Looping through timeslices')\n",
    "    for timerange in timeranges:\n",
    "        #mid_date=timerange[1][:-2]+'01'\n",
    "        mid_date=timerange[2]\n",
    "        #filter by time period\n",
    "        #STEP 1: THE MONTHLY SLICES\n",
    "        #--------------------------\n",
    "        rc_month=my_col.filterByTime (timerange[0], timerange[1], 'AcquisitionDate', date_time_format = '%Y-%m-%d')\n",
    "        try:\n",
    "            print ('Working on {} with: {} rasters'.format(mid_date,rc_month.count))\n",
    "            #first remove the clouds\n",
    "            time_reporter('Mapping cloud removal function')\n",
    "            month_cloudfree=rc_month.map(remove_cloud)\n",
    "            #now we need to decide on which median is used\n",
    "            if average_to_use=='MEDIAN':\n",
    "                time_reporter('Simple MEDIAN calculation')\n",
    "                try:\n",
    "                    month_acc = month_cloudfree.median(ignore_nodata = True, extent_type = 'UnionOf')\n",
    "                    month_acc_output=os.path.join(TEMP_Folder,'acc_'+str(rc_month.count)+'_median_'+mid_date+'.tif')\n",
    "                    #always output as 16bit integer!\n",
    "                    if output_band_mode=='3IDX':\n",
    "                        arcpy.management.CopyRaster(month_acc, month_acc_output, config_keyword=None, pixel_type='16_BIT_UNSIGNED', background_value=None, nodata_value=0, format='COG')\n",
    "                        #month_acc.save(month_acc_output)\n",
    "                    else:\n",
    "                        arcpy.management.CopyRaster(month_acc, month_acc_output, config_keyword=None, pixel_type='16_BIT_UNSIGNED', background_value=None, nodata_value=0, format='COG')\n",
    "                except Exception as exp:\n",
    "                    print (exp)\n",
    "            elif average_to_use=='MEAN':        \n",
    "                time_reporter('Simple MEAN calculation')\n",
    "                try:\n",
    "                    month_acc = month_cloudfree.mean(ignore_nodata = True, extent_type = 'UnionOf')\n",
    "                    month_acc_output=os.path.join(TEMP_Folder,'acc_'+str(rc_month.count)+'_mean_'+mid_date+'.tif')\n",
    "                    if output_band_mode=='3IDX':\n",
    "                        #month_acc.save(month_acc_output)\n",
    "                        arcpy.management.CopyRaster(month_acc, month_acc_output, config_keyword=None, pixel_type='16_BIT_UNSIGNED', background_value=None, nodata_value=0, format='COG')\n",
    "                    else:\n",
    "                        arcpy.management.CopyRaster(month_acc, month_acc_output, config_keyword=None, pixel_type='16_BIT_UNSIGNED', background_value=None, nodata_value=0, format='COG')\n",
    "                except Exception as exp:\n",
    "                    print (exp)\n",
    "\n",
    "            else: #thats the GEOMETRIC MEDIAN that does not work porperly - we also have to use intermediate files more\n",
    "                time_reporter('GEOMETRIC MEDIAN calculation')\n",
    "                try:\n",
    "                    #we need a physical file here - fails if trying to do in memory\n",
    "                    temp_multidim=month_cloudfree.toMultidimensionalRaster(variable_field_name = \"Name\", dimension_field_names = \"AcquisitionDate\")\n",
    "                    cloudfree_outpath=os.path.normpath(os.path.join(TEMP_Folder,'cloudfree_'+str(rc_month.count)+'_'+mid_date+'.crf'))\n",
    "                    temp_multidim.save(cloudfree_outpath)\n",
    "                    #now we can continue similar to above\n",
    "                    month_acc=GeometricMedian(temp_multidim.catalogPath, epsilon=25, max_iteration=rc_month.count-2, extent_type='UnionOf', cellsize_type='FirstOf')\n",
    "                    month_acc_output=os.path.join(TEMP_Folder,'acc_'+str(rc_month.count)+'_geometric_'+mid_date+'.tif')\n",
    "                    #adjust the pixel type depending on mode\n",
    "                    if output_band_mode=='3IDX':\n",
    "                        arcpy.management.CopyRaster(month_acc, month_acc_output, config_keyword=None, pixel_type='16_BIT_UNSIGNED', background_value=None, nodata_value=0, format='COG')\n",
    "                    else:\n",
    "                        arcpy.management.CopyRaster(month_acc, month_acc_output, config_keyword=None, pixel_type='16_BIT_UNSIGNED', background_value=None, nodata_value=0, format='COG')\n",
    " \n",
    "                    arcpy.management.CopyRaster(month_acc, month_acc_output, config_keyword=None, pixel_type='16_BIT_UNSIGNED', background_value=None, nodata_value=0, format='COG')\n",
    "                except Exception as exp:\n",
    "                    print (exp)   \n",
    "            #now add the result to the respective lists\n",
    "            monthly_rasters.append(month_acc_output)\n",
    "            monthly_dates.append(mid_date)\n",
    "            #and we can do some clean_up\n",
    "            #we dont need month_cloudfree anymore, delete\n",
    "            del month_cloudfree\n",
    "            #there is more we dont need if the version was GEOMETRIC MEDIAN\n",
    "            if average_to_use=='GEOMETRIC':\n",
    "                #we dont need the cloudfree stored version anymore\n",
    "                del temp_multidim\n",
    "                arcpy.Delete_management(cloudfree_outpath)\n",
    "        except Exception as exp:\n",
    "            print ('Error during monthly slice generation/nDetails {}'.format(exp))\n",
    "        print ('Finished processing Slice {}'.format(mid_date))    \n",
    "    #STEP 2: RE-CREATE A RASTER COLLECTION FROM THE MONTHLY AVERAGED SLICES\n",
    "    #----------------------------------------------------\n",
    "    print ('-------------------------------')\n",
    "    time_reporter('Create new Multidim raster')\n",
    "    try:\n",
    "        the_dict={'StdTime':monthly_dates,'datestr':monthly_dates}\n",
    "        monthly_rc=arcpy.ia.RasterCollection(monthly_rasters,the_dict)\n",
    "        print ('New Collection has {} images'.format(monthly_rc.count))\n",
    "        print ('Fields in collection: {}'.format(monthly_rc.fields))\n",
    "        #apply the band combination/selection desired\n",
    "        if output_band_mode=='3IDX':\n",
    "            outband_rc=monthly_rc.map(ThreeIndices)\n",
    "            mdim_outpath=os.path.join(RESULT_Folder,os.path.basename(input_md)+'_3idx.crf')\n",
    "            print (mdim_outpath)\n",
    "        else: #the 7 band mode\n",
    "            outband_rc=monthly_rc.map(SevenBands)\n",
    "            mdim_outpath=os.path.join(RESULT_Folder,os.path.basename(input_md)+'_7bnd.crf')           \n",
    "        #and save the output plus do cleanup\n",
    "        time_reporter('Safe final output')\n",
    "        mdim_raster = outband_rc.toMultidimensionalRaster(variable_field_name = \"name\", dimension_field_names = 'StdTime')\n",
    "        mdim_raster.save(mdim_outpath)\n",
    "\n",
    "        #there are locking issues with mdim_raster - clean up temp datasets and variables\n",
    "        #work with the path for the following steps\n",
    "        try:\n",
    "            del mdim_raster\n",
    "            del outband_rc\n",
    "            del monthly_rc\n",
    "            del in_md_Layer\n",
    "            del in_boundary\n",
    "            arcpy.Delete_management('in_MDLayer')\n",
    "        except Exception as exp:\n",
    "            print (exp)\n",
    "            pass\n",
    "            \n",
    "        #reassign the bands again :(\n",
    "        time_reporter('Re-assigning bands')\n",
    "        reassign_band_names(mdim_outpath)\n",
    "\n",
    "        #build the multidimensional transpose on it\n",
    "        time_reporter('Multidimensional transpose')\n",
    "        arcpy.md.BuildMultidimensionalTranspose(\n",
    "            in_multidimensional_raster=mdim_outpath,\n",
    "            delete_transpose=\"NO_DELETE_TRANSPOSE\")\n",
    "\n",
    "        #apply predefined rfts to the result\n",
    "        time_reporter('Append rfts')\n",
    "        append_rfts_to_raster(mdim_outpath)\n",
    "\n",
    "    except Exception as exp:\n",
    "        print ('Error during re-creation of Multidim raster/Details {}'.format(exp))\n",
    "            \n",
    "    #STEP 3 - little cleanup of written temp files\n",
    "    #---------------------------------------------\n",
    "    time_reporter('Cleanup')\n",
    "    arcpy.env.workspace=TEMP_Folder\n",
    "    try:\n",
    "        for dataset in arcpy.ListRasters('acc*.tif'):\n",
    "            fullpath=os.path.join(arcpy.env.workspace,dataset)\n",
    "            arcpy.Delete_management(fullpath)\n",
    "        #take care of output_band_mode selected\n",
    "        if output_band_mode=='3IDX':\n",
    "            for dataset in arcpy.ListRasters('three*.tif'):\n",
    "                fullpath=os.path.join(arcpy.env.workspace,dataset)\n",
    "                arcpy.Delete_management(fullpath)  \n",
    "        else: #the 7band mode\n",
    "            for dataset in arcpy.ListRasters('seven*.tif'):\n",
    "                fullpath=os.path.join(arcpy.env.workspace,dataset)\n",
    "                arcpy.Delete_management(fullpath)  \n",
    "            \n",
    "    except Exception as exp:\n",
    "        print ('Error during cleanup/Details {}'.format(exp))\n",
    "                                \n",
    "    print ('Finished processing MD {}'.format(input_md))\n",
    "    print ('Final result written to {}'.format(mdim_outpath))\n",
    "    print ('----------------------------------------')                            \n",
    "\n",
    "    #STEP 4: - create a single polygon per result, that delineates\n",
    "    #------------------------------------------------------------\n",
    "    #the part of the result that has valid pixels for every time-slice\n",
    "    #this is needed for the training sample generation\n",
    "    #this polygon will be saved in the same fGDB as the original mosac\n",
    "    create_full_coverage_polygon(mdim_outpath,item[1],theyear)        \n",
    "print ('All done.')            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcpy.Delete_management('in_MDLayer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
